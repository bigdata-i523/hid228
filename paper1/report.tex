\documentclass[sigconf]{acmart}

\input{format/i523}
\usepackage{hyperref}

\usepackage{endfloat}
\renewcommand{\efloatseparator}{\mbox{}} % no new page between figures

\usepackage{booktabs} % For formal tables

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\begin{document}
\title{Big Data Applications in Electric Power Distribution}


\author{Swargam, Prashanth}
\affiliation{%
  \institution{Indiana University Bloomington}
  \streetaddress{107 S Indiana Ave}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{pswargam@iu.edu}


% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{B. Trovato et al.}


\begin{abstract}
Now-a-days, the process of storing the power measurements have changed. Conventional meters are replaced by the smart meters. New distribution management systems like SCADA and AMI are implemented to monitor power distribution. These smart meters record the readings and communicate the data to the server. However, these systems are designed to generate the readings very frequently i.e., 15 minutes to an hour. Upon that, smart meters are being deployed at every possible location to improve the accuracy of the data. This advancements in electric power distribution system results in enormous amounts of data which requires advance analytics to process, analyse and store data. This paper discusses about the implementation of Big Data technologies, challenges of implementing Big Data in Electric Power Distribution Systems.
\end{abstract}

\keywords{HID228, I523, Big Data, Power Distribution,Smart Power}

\maketitle

\section{Introduction}

Volume of data is increasing. According to Ref \cite{44zeta}, it is said that, world's data utilization will increase to 44 zettabytes from the current utilization of 4.4 zettabytes. To process this data, Big Data analytics will be useful. But, instantiating a big data architecture is not easy task. 

In electrical Power Distribution industry, data deluge is picking its pace. The data which was recorded for month, is now being noted for very small intervals. This quadruples  the amount of data that should be process. There is a lot of potential work to be put in for designing a good Big Data architecture to process and analyse this data. Most of the power generation units are developing their infrastructure to support these designs.

\subsection{4 v's in Big Data in Power Distribution System}

Big Data is mostly described in 4 v's. Each of this V's are considerable factors in a Big Data Solution\cite{A.Munshi2017}.

Volume: The data is periodically generated by many data sources like smart meters, machines and other appliances.

Variety: Each data source in electric power distribution system is explicit to each other. Each source has its own frequency of data generation and its own method of data generation. Thus, the data is heterogenous.

Velocity: is the speed at which the data is available for the end user.

Veracity: It deals with the correctness of the data. As all the data collected by sensors, meter tend to have various losses, correction algorithms should be defined to find the accurate data. Their might be chances for data transfer losses.

\section{Data Sources}

Smart meters which are placed at customer's vicinity will record the consumption of a specific group of customers. This data can be used to analyse the behaviour of customer for certain circumstances of weather and environment.

Distribution systems which manage the distribution of power, generate large amount of data related to voltages and currents at various levels of distribution. This data is very important in analysing the load level and demand for the distribution circle\cite{Ali2013}.

 Phasor measuring units at generation. This data is used to analyse the behaviour of generator and amount of power generation that will be required to supply enough power. This data will be used to decide the functioning of generators\cite{ShadyS.Refaat2016}.
 
Old market data will be used to analyse the pricing and marketing strategies. These data is more focused on users and their behaviour.

\section{Data Integration}

\subsection{Service Oriented Model}

 This model has a workflow which is defined in Business process Enterprise Language often referred as WS BPEL\cite{WSBPEL}. WS BPEL is used for is enterprise language used for automating a business process. BPEL files defines the process to be followed by a request from the web services. In this model, All the user requests are handled by services. These services either connect to the storage resources or calls the other services based on the process model defined in BPEL. This modelling ensures data is being utilised in a structural manner and analysed according to the process model.

Interfacing services: 
This service is used to manage the interfaces with the end user. This services generally initiates calls to a process defined in WS BPEL. After all the other processes which are defined in process model are completed, this service is used to project the analytical data to the user at the end of execution. In this case, this service receives data from one of the process models\cite{Pathak}.

Execution Service:
This service is responsible for all the logic involved in modelling the data. For the common requests, these are well documented in BPEL files. These documents specify the set of instructions to be followed to model the data as per the request from the service. This service uses a Information management services to establish a data link to data storages.\cite{Pathak}

Pooling Services:
All the data requests coming from Information management services are  managed by pooling services. This service help the other services in establishing a dynamic connection to data storages. This service also handles one way communication between the data storages and Information management services. This is called event-driven approach. All the activities like addition of data, removal of data  in data storages are considered as event. This events are communicated to the information management services. 

\section{Data Storage and Processing}
\subsection{Hadoop and MapReduce}
Hadoop and MapReduce are prevalent technologies in storing and processing data. Hadoop has a database in file system called as HDFS\cite{hadoop}. HDFS and MapReduce is an Apache Project which is used to split the data into various segments and store the data in various commodity boxes. This boxes are clustered together to allow the flow of data between them.

As the data is generated at different physical locations, it will be easy to store data at different geographical locations. There will be minimal transmission of data. Changes in electrical grid doesn't require the change in entire data model. On addition or deletion of a electrical node, a new data storage can be added without any intervention to the existing data storages. This distributed model also ensures high availability. Availability of one data source will have minimal or no effect on the availability of the system thus reducing the downtime and business losses.

The data from various sources have different formats. This makes it difficult to store data in traditional relational databases because of type conversions and relational handling. Hadoop overcomes this problem by storing the data in filesystems. Data can be easily pre-processed and stored in the pictorial representations rather than in tables and schemas.

Mapreduce is a programming model. This has two components i.e., Jobtracker and Tasktracker. Jobtracker is a master process which is responsible for scheduling assigning the jobs to Tasktracker. Tasktracker is responsible for execution of the mapreduce jobs.A sample mapreduce task takes has two phases\cite{tutorials}. The first phase is a map phase, where the data is divided into several pieces. The second stage is reduce phase, where the data is processed to produce output.These mapreduce jobs are scheduled and run in batches.This is called Batch Processing.

 This map and reduce functions are very reliable in analysing the nature and demand of customer from the data available from the most recent processed jobs. Mapreduce jobs run on static data. This will not serve the requests like load analysis, electrical machinery failure, metering failure, power loss which require real time data\cite{BigDataAnalyticsPlatformforSmartGrid2015}. 

\subsection{Apache Spark for Realtime data}
Apache Spark is a cluster computing model. It has capability to perform real time analysis of data. IT is nurtured with more enhanced machine learning algorithm and libraries\cite{Zaharia}. Spark SQL, MLlib, Spark streaming, GraphX are some of those. Spark framework contains data in distributed sets. It also has set of working programs on the distributed sets of data. This set of programs are called Resilient Distributed Dataset functions\cite{Tu2016}.

The dynamics of electrical properties changes in milliseconds. In order, to collect these dynamics, the power measuring systems  have evolved . New instruments like phasor measurement units have evolved. These devices collect data at the rate of 20-40 readings per second. However, if there is any delay in processing such huge amount of data, then the collected data is not useful. Apache spark tackles this issue in two different approaches.

Streaming Approach: Streaming approach reacts to the each and every event that occurs in the data. As soon as new data is injected, all the resilient distributed dataset functions are called. This function processes data and makes them into a usable format and stores them\cite{Zaharia}. This kind of approach is used in metering, billing and load management. 

Iterative approach:\cite{2013} In this approach, spark offers in memory computing. The datasets are accessed in memory instead of the going to the physical database. All the phasor readings which are required by multiple requests to calculate state space estimation use the developed cache data on the servers instead of accessing them from the data storage. This make requests like state space calculation much lighter.

\section{Challenges in Implementing Big Data}
\subsection{Information Security}
A large amount of customer electricity usage data is collected. This data must be protected from data leaks. Access control systems must be enhanced to restrict the access to the customer data. Leaked data can be exploited to trace the end user and his/her appliances\cite{Yu}.

\subsection{Asset Management}
Assets are the power collection units. These are one of the important devices in the architecture. All the assets must be maintained properly to ensure the quality of data. If any of the power measuring unit goes down or malfunctions, there will be discrepancy in analysing data. This will lead to improper decisions.

\subsection{Adaptability}
The amount of data in increasing by many folds. In present world, Data Analytics has become a part of Electrical Industry. Though, Many Power Industries have implemented Big Data solutions, there are many industries which are yet to implement Big Data technologies. Most of the South asian countries still use SCADA for processing electrical Data\cite{2002}.
\section{conclusion}


This brief description highlights the advancements of Big Data Solutions in Power distribution systems. Firstly, Data sources for analytic systems in power distribution like smart meters, Phasor measurement units are briefed. Integration of Data from various sources using service oriented architecture and the important processes in the service oriented architecture are discussed. Later, Implementation of distributed file system i.e., HDFS with processing models like MapReduce and Apache Spark are discussed. At last, challenges like information security, asset management and adaptability of Big Data Technologies are discussed. 
\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

\end{document}
